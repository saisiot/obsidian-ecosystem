#!/usr/bin/env python3
"""
v1.0 â†’ v2.0 Migration Script

This script migrates the Obsidian RAG MCP from v1.0 to v2.0 by:
1. Backing up existing metadata
2. Upgrading metadata schema
3. Initializing new stores (NetworkMetadata, RepomixIndex)
4. Re-indexing vault to populate new stores (ChromaDB is preserved)
"""

import argparse
import json
import shutil
import sys
import traceback
from datetime import datetime
from pathlib import Path

# Add src to path
sys.path.insert(0, str(Path(__file__).parent.parent / "src"))

from config import METADATA_FILE, PROJECT_ROOT, VAULT_PATH
from indexer import UnifiedIndexer
from network_store import NetworkMetadataStore
from repomix_store import RepomixIndexStore
from vector_store import VectorStore


class Colors:
    """ANSI color codes for terminal output"""

    HEADER = "\033[95m"
    OKBLUE = "\033[94m"
    OKCYAN = "\033[96m"
    OKGREEN = "\033[92m"
    WARNING = "\033[93m"
    FAIL = "\033[91m"
    ENDC = "\033[0m"
    BOLD = "\033[1m"
    UNDERLINE = "\033[4m"


def colored(text: str, color: str) -> str:
    """Apply color to text"""
    return f"{color}{text}{Colors.ENDC}"


def print_header(text: str):
    """Print a styled header"""
    print()
    print(colored("â•”" + "â•" * 58 + "â•—", Colors.BOLD))
    print(colored("â•‘" + " " * 58 + "â•‘", Colors.BOLD))
    print(colored("â•‘" + text.center(58) + "â•‘", Colors.BOLD))
    print(colored("â•‘" + " " * 58 + "â•‘", Colors.BOLD))
    print(colored("â•š" + "â•" * 58 + "â•", Colors.BOLD))


def print_step(step_num: int, title: str):
    """Print a step header"""
    print()
    print(colored(f"\n{title}", Colors.BOLD))
    print(colored("â”" * 60, Colors.OKBLUE))


def backup_metadata(dry_run: bool = False, verbose: bool = False) -> Path:
    """v1.0 ë©”íƒ€ë°ì´í„° ë°±ì—…

    Args:
        dry_run: ì‹¤ì œ ì‘ì—… ìˆ˜í–‰í•˜ì§€ ì•Šê³  ì‹œë®¬ë ˆì´ì…˜ë§Œ
        verbose: ìƒì„¸ ë¡œê·¸ ì¶œë ¥

    Returns:
        ë°±ì—… íŒŒì¼ ê²½ë¡œ
    """
    print_step(1, "ğŸ“¦ Step 1: v1.0 ë©”íƒ€ë°ì´í„° ë°±ì—…")

    backup_file = METADATA_FILE.with_suffix(".json.v1.backup")

    if verbose:
        print(f"  ì›ë³¸: {METADATA_FILE}")
        print(f"  ë°±ì—…: {backup_file}")

    if METADATA_FILE.exists():
        if not dry_run:
            shutil.copy(METADATA_FILE, backup_file)
        print(colored(f"âœ… ë°±ì—… ì™„ë£Œ: {backup_file}", Colors.OKGREEN))
    else:
        print(colored("âš ï¸ ê¸°ì¡´ ë©”íƒ€ë°ì´í„° íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤.", Colors.WARNING))

    return backup_file


def upgrade_metadata_schema(
    dry_run: bool = False, verbose: bool = False
) -> dict:
    """ë©”íƒ€ë°ì´í„° ìŠ¤í‚¤ë§ˆ v2.0ìœ¼ë¡œ ì—…ê·¸ë ˆì´ë“œ

    Args:
        dry_run: ì‹¤ì œ ì‘ì—… ìˆ˜í–‰í•˜ì§€ ì•Šê³  ì‹œë®¬ë ˆì´ì…˜ë§Œ
        verbose: ìƒì„¸ ë¡œê·¸ ì¶œë ¥

    Returns:
        ì—…ê·¸ë ˆì´ë“œëœ ë©”íƒ€ë°ì´í„°
    """
    print_step(2, "ğŸ”„ Step 2: ë©”íƒ€ë°ì´í„° ìŠ¤í‚¤ë§ˆ ì—…ê·¸ë ˆì´ë“œ")

    if not METADATA_FILE.exists():
        print(
            colored("âš ï¸ ë©”íƒ€ë°ì´í„° íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤. ìƒˆë¡œ ìƒì„±ë©ë‹ˆë‹¤.", Colors.WARNING)
        )
        metadata = {"last_update": 0, "indexed_files": {}}
    else:
        with open(METADATA_FILE, "r") as f:
            metadata = json.load(f)

        if verbose:
            print(f"  ê¸°ì¡´ ë²„ì „: {metadata.get('version', 'v1.0 (ì—†ìŒ)')}")
            print(f"  ë§ˆì§€ë§‰ ì—…ë°ì´íŠ¸: {metadata.get('last_update', 0)}")
            print(f"  ì¸ë±ìŠ¤ëœ íŒŒì¼ ìˆ˜: {len(metadata.get('indexed_files', {}))}")

    # v2.0 ìŠ¤í‚¤ë§ˆ ì¶”ê°€
    metadata["version"] = "2.0.0"
    metadata["databases"] = {
        "chromadb": {"last_update": metadata.get("last_update", 0)},
        "network": {"last_update": None},
        "repomix": {"last_update": None},
    }
    metadata["auto_update"] = {
        "enabled": True,
        "interval": 300,
        "last_run": None,
    }

    if verbose:
        print("\n  ì—…ê·¸ë ˆì´ë“œëœ ìŠ¤í‚¤ë§ˆ:")
        print(f"    - version: {metadata['version']}")
        print(f"    - databases: {list(metadata['databases'].keys())}")
        print(f"    - auto_update.enabled: {metadata['auto_update']['enabled']}")

    # ì €ì¥
    if not dry_run:
        with open(METADATA_FILE, "w") as f:
            json.dump(metadata, f, indent=2)

    print(colored(f"âœ… ìŠ¤í‚¤ë§ˆ ì—…ê·¸ë ˆì´ë“œ ì™„ë£Œ (v2.0.0)", Colors.OKGREEN))
    print(f"   - ë°ì´í„°ë² ì´ìŠ¤: ChromaDB, Network, Repomix")
    print(f"   - Auto-update: Enabled (300ì´ˆ ê°„ê²©)")

    return metadata


def initialize_new_stores(
    dry_run: bool = False, verbose: bool = False
) -> tuple:
    """ìƒˆë¡œìš´ Store ì´ˆê¸°í™”

    Args:
        dry_run: ì‹¤ì œ ì‘ì—… ìˆ˜í–‰í•˜ì§€ ì•Šê³  ì‹œë®¬ë ˆì´ì…˜ë§Œ
        verbose: ìƒì„¸ ë¡œê·¸ ì¶œë ¥

    Returns:
        (vector_store, network_store, repomix_store) íŠœí”Œ
    """
    print_step(3, "ğŸ†• Step 3: ìƒˆë¡œìš´ ë°ì´í„°ë² ì´ìŠ¤ ì´ˆê¸°í™”")

    if dry_run:
        print(colored("  [DRY RUN] Store ì´ˆê¸°í™” ì‹œë®¬ë ˆì´ì…˜", Colors.OKCYAN))
        return None, None, None

    vector_store = VectorStore()
    network_store = NetworkMetadataStore()
    repomix_store = RepomixIndexStore()

    if verbose:
        print(f"  - VectorStore: {vector_store.collection.name}")
        print(f"  - NetworkMetadataStore: {network_store.metadata_file}")
        print(f"  - RepomixIndexStore: {repomix_store.index_file}")

    print(colored(f"âœ… VectorStore ì´ˆê¸°í™” ì™„ë£Œ", Colors.OKGREEN))
    print(colored(f"âœ… NetworkMetadataStore ì´ˆê¸°í™” ì™„ë£Œ", Colors.OKGREEN))
    print(colored(f"âœ… RepomixIndexStore ì´ˆê¸°í™” ì™„ë£Œ", Colors.OKGREEN))

    return vector_store, network_store, repomix_store


def reindex_vault(
    vector_store,
    network_store,
    repomix_store,
    dry_run: bool = False,
    verbose: bool = False,
) -> bool:
    """Vault ì¬ì¸ë±ì‹± (Networkì™€ Repomixë§Œ)

    Args:
        vector_store: VectorStore ì¸ìŠ¤í„´ìŠ¤
        network_store: NetworkMetadataStore ì¸ìŠ¤í„´ìŠ¤
        repomix_store: RepomixIndexStore ì¸ìŠ¤í„´ìŠ¤
        dry_run: ì‹¤ì œ ì‘ì—… ìˆ˜í–‰í•˜ì§€ ì•Šê³  ì‹œë®¬ë ˆì´ì…˜ë§Œ
        verbose: ìƒì„¸ ë¡œê·¸ ì¶œë ¥

    Returns:
        ì„±ê³µ ì—¬ë¶€
    """
    print_step(4, "ğŸ” Step 4: Vault ì¬ì¸ë±ì‹±")
    print("â„¹ï¸  ChromaDBëŠ” ë³´ì¡´ë˜ë©°, Networkì™€ Repomixë§Œ ìƒì„±ë©ë‹ˆë‹¤.")
    print()

    # Vault ì¡´ì¬ í™•ì¸
    if not VAULT_PATH.exists():
        print(
            colored(f"âŒ Vault ê²½ë¡œê°€ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤: {VAULT_PATH}", Colors.FAIL)
        )
        print(colored("âš ï¸  config.pyì˜ VAULT_PATHë¥¼ í™•ì¸í•˜ì„¸ìš”.", Colors.WARNING))
        return False

    # ë§ˆí¬ë‹¤ìš´ íŒŒì¼ ìˆ˜ í™•ì¸
    md_files = list(VAULT_PATH.rglob("*.md"))
    print(f"ğŸ“‚ ë°œê²¬ëœ ë§ˆí¬ë‹¤ìš´ íŒŒì¼: {len(md_files)}ê°œ")

    if verbose and len(md_files) > 0:
        print("\n  íŒŒì¼ ëª©ë¡ (ìµœëŒ€ 10ê°œ):")
        for file in md_files[:10]:
            print(f"    - {file.name}")
        if len(md_files) > 10:
            print(f"    ... ê·¸ ì™¸ {len(md_files) - 10}ê°œ")

    if len(md_files) == 0:
        print(colored("âš ï¸ ë§ˆí¬ë‹¤ìš´ íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤. ì¬ì¸ë±ì‹±ì„ ê±´ë„ˆëœë‹ˆë‹¤.", Colors.WARNING))
        return True

    if dry_run:
        print(colored("  [DRY RUN] ì¬ì¸ë±ì‹± ì‹œë®¬ë ˆì´ì…˜", Colors.OKCYAN))
        print(f"  ì˜ˆìƒ ì‘ì—…: {len(md_files)}ê°œ íŒŒì¼ ì¸ë±ì‹±")
        return True

    # UnifiedIndexer ìƒì„±
    indexer = UnifiedIndexer(vector_store, network_store, repomix_store)

    # ì¬ì¸ë±ì‹± ì‹¤í–‰
    print("\nâ³ ì¬ì¸ë±ì‹± ì‹œì‘... (ìˆ˜ ë¶„ ì†Œìš”ë  ìˆ˜ ìˆìŠµë‹ˆë‹¤)")
    start_time = datetime.now()

    try:
        indexer.update_index()

        elapsed = (datetime.now() - start_time).total_seconds()
        print(
            colored(
                f"\nâœ… ì¬ì¸ë±ì‹± ì™„ë£Œ! (ì†Œìš” ì‹œê°„: {elapsed:.1f}ì´ˆ)", Colors.OKGREEN
            )
        )

        # í†µê³„ ì¶œë ¥
        print("\nğŸ“Š ì¸ë±ì‹± í†µê³„:")
        chroma_count = len(vector_store.collection.get()["ids"])
        network_count = len(network_store.metadata["files"])
        repomix_count = len(repomix_store.index["files"])

        print(f"   - ChromaDB: {chroma_count} ì²­í¬")
        print(f"   - Network: {network_count} íŒŒì¼")
        print(f"   - Repomix: {repomix_count} íŒŒì¼")

        if verbose:
            print("\n  Network í†µê³„:")
            stats = network_store.get_network_stats()
            print(f"    - ì´ íŒŒì¼: {stats['total_files']}")
            print(f"    - ì´ ë°±ë§í¬: {stats['total_backlinks']}")
            print(f"    - ê³ ë¦½ëœ ë…¸íŠ¸: {stats['orphaned_notes']}")

            print("\n  Repomix í†µê³„:")
            rep_stats = repomix_store.index["stats"]
            print(f"    - ì´ ë‹¨ì–´: {rep_stats['total_words']:,}")
            print(f"    - ì˜ˆìƒ í† í°: {rep_stats['total_tokens_estimated']:,}")

        return True

    except Exception as e:
        print(colored(f"\nâŒ ì¬ì¸ë±ì‹± ì‹¤íŒ¨: {e}", Colors.FAIL))
        if verbose:
            traceback.print_exc()
        return False


def verify_migration(verbose: bool = False) -> bool:
    """ë§ˆì´ê·¸ë ˆì´ì…˜ ê²€ì¦

    Args:
        verbose: ìƒì„¸ ë¡œê·¸ ì¶œë ¥

    Returns:
        ê²€ì¦ ì„±ê³µ ì—¬ë¶€
    """
    print_step(5, "âœ… Step 5: ë§ˆì´ê·¸ë ˆì´ì…˜ ê²€ì¦")

    checks = []

    # 1. ë©”íƒ€ë°ì´í„° íŒŒì¼ ì¡´ì¬ í™•ì¸
    checks.append(("index_metadata.json", METADATA_FILE.exists()))

    # 2. Network ë©”íƒ€ë°ì´í„° ì¡´ì¬ í™•ì¸
    network_file = PROJECT_ROOT / "data" / "network_metadata.json"
    checks.append(("network_metadata.json", network_file.exists()))

    # 3. Repomix ì¸ë±ìŠ¤ ì¡´ì¬ í™•ì¸
    repomix_file = PROJECT_ROOT / "data" / "repomix_index.json"
    checks.append(("repomix_index.json", repomix_file.exists()))

    # 4. ë°±ì—… ì¡´ì¬ í™•ì¸
    backup_file = METADATA_FILE.with_suffix(".json.v1.backup")
    checks.append(("v1.0 ë°±ì—…", backup_file.exists()))

    # ê²°ê³¼ ì¶œë ¥
    all_passed = True
    for name, passed in checks:
        if passed:
            print(colored(f"âœ… {name}", Colors.OKGREEN))
        else:
            print(colored(f"âŒ {name}", Colors.FAIL))
            all_passed = False

    if verbose and all_passed:
        print("\n  ìƒì„¸ ì •ë³´:")
        # ë©”íƒ€ë°ì´í„° ë²„ì „ í™•ì¸
        if METADATA_FILE.exists():
            with open(METADATA_FILE, "r") as f:
                metadata = json.load(f)
            print(f"    - ë©”íƒ€ë°ì´í„° ë²„ì „: {metadata.get('version', 'N/A')}")
            print(
                f"    - ë°ì´í„°ë² ì´ìŠ¤: {list(metadata.get('databases', {}).keys())}"
            )

    return all_passed


def rollback_migration(verbose: bool = False) -> bool:
    """ë§ˆì´ê·¸ë ˆì´ì…˜ ë¡¤ë°±

    Args:
        verbose: ìƒì„¸ ë¡œê·¸ ì¶œë ¥

    Returns:
        ë¡¤ë°± ì„±ê³µ ì—¬ë¶€
    """
    print_header("ğŸ”™ ë§ˆì´ê·¸ë ˆì´ì…˜ ë¡¤ë°±")
    print()

    backup_file = METADATA_FILE.with_suffix(".json.v1.backup")

    if not backup_file.exists():
        print(
            colored(f"âŒ ë°±ì—… íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤: {backup_file}", Colors.FAIL)
        )
        return False

    try:
        print(f"â³ ë¡¤ë°± ì¤‘...")

        # ë°±ì—… íŒŒì¼ ë³µì›
        shutil.copy(backup_file, METADATA_FILE)

        # v2.0 íŒŒì¼ ì‚­ì œ
        network_file = PROJECT_ROOT / "data" / "network_metadata.json"
        repomix_file = PROJECT_ROOT / "data" / "repomix_index.json"

        if network_file.exists():
            network_file.unlink()
            if verbose:
                print(f"  - ì‚­ì œ: {network_file}")

        if repomix_file.exists():
            repomix_file.unlink()
            if verbose:
                print(f"  - ì‚­ì œ: {repomix_file}")

        print(colored("\nâœ… ë¡¤ë°± ì™„ë£Œ!", Colors.OKGREEN))
        print(f"   v1.0 ë©”íƒ€ë°ì´í„°ë¡œ ë³µì›ë˜ì—ˆìŠµë‹ˆë‹¤.")
        return True

    except Exception as e:
        print(colored(f"\nâŒ ë¡¤ë°± ì‹¤íŒ¨: {e}", Colors.FAIL))
        if verbose:
            traceback.print_exc()
        return False


def main():
    """ë©”ì¸ ë§ˆì´ê·¸ë ˆì´ì…˜ í”„ë¡œì„¸ìŠ¤"""
    parser = argparse.ArgumentParser(
        description="Obsidian RAG MCP v1.0 â†’ v2.0 ë§ˆì´ê·¸ë ˆì´ì…˜ ìŠ¤í¬ë¦½íŠ¸"
    )
    parser.add_argument(
        "--dry-run",
        action="store_true",
        help="ì‹¤ì œ ì‘ì—…ì„ ìˆ˜í–‰í•˜ì§€ ì•Šê³  ì‹œë®¬ë ˆì´ì…˜ë§Œ ì‹¤í–‰",
    )
    parser.add_argument(
        "--rollback",
        action="store_true",
        help="ë§ˆì´ê·¸ë ˆì´ì…˜ ë¡¤ë°± (v1.0ìœ¼ë¡œ ë³µì›)",
    )
    parser.add_argument(
        "--verbose", "-v", action="store_true", help="ìƒì„¸ ë¡œê·¸ ì¶œë ¥"
    )

    args = parser.parse_args()

    # ë¡¤ë°± ëª¨ë“œ
    if args.rollback:
        success = rollback_migration(verbose=args.verbose)
        return 0 if success else 1

    # ì¼ë°˜ ë§ˆì´ê·¸ë ˆì´ì…˜ ëª¨ë“œ
    print_header("Obsidian RAG MCP v1.0 â†’ v2.0 Migration")

    if args.dry_run:
        print(
            colored(
                "\nâš ï¸  DRY RUN ëª¨ë“œ: ì‹¤ì œ ì‘ì—…ì€ ìˆ˜í–‰ë˜ì§€ ì•ŠìŠµë‹ˆë‹¤.", Colors.WARNING
            )
        )

    try:
        # Step 1: ë°±ì—…
        backup_file = backup_metadata(dry_run=args.dry_run, verbose=args.verbose)

        # Step 2: ìŠ¤í‚¤ë§ˆ ì—…ê·¸ë ˆì´ë“œ
        metadata = upgrade_metadata_schema(
            dry_run=args.dry_run, verbose=args.verbose
        )

        # Step 3: ìƒˆ Store ì´ˆê¸°í™”
        vector_store, network_store, repomix_store = initialize_new_stores(
            dry_run=args.dry_run, verbose=args.verbose
        )

        # Step 4: ì¬ì¸ë±ì‹±
        if not args.dry_run:
            success = reindex_vault(
                vector_store,
                network_store,
                repomix_store,
                dry_run=args.dry_run,
                verbose=args.verbose,
            )

            if not success:
                print(colored("\nâŒ ë§ˆì´ê·¸ë ˆì´ì…˜ ì‹¤íŒ¨!", Colors.FAIL))
                print(colored(f"ğŸ’¡ ë¡¤ë°± ë°©ë²•: python {__file__} --rollback", Colors.OKCYAN))
                return 1

        # Step 5: ê²€ì¦
        if not args.dry_run:
            if not verify_migration(verbose=args.verbose):
                print(
                    colored(
                        "\nâš ï¸ ê²€ì¦ ì‹¤íŒ¨. ì¼ë¶€ íŒŒì¼ì´ ëˆ„ë½ë˜ì—ˆìŠµë‹ˆë‹¤.", Colors.WARNING
                    )
                )
                return 1

        # ì„±ê³µ!
        print("\n" + colored("â”" * 60, Colors.OKBLUE))
        print(colored("ğŸ‰ ë§ˆì´ê·¸ë ˆì´ì…˜ ì™„ë£Œ!", Colors.OKGREEN + Colors.BOLD))
        print(colored("â”" * 60, Colors.OKBLUE))

        if not args.dry_run:
            print("\nâœ… v2.0 ê¸°ëŠ¥:")
            print("   - 3ê°œ ë°ì´í„°ë² ì´ìŠ¤ í†µí•© (ChromaDB, Network, Repomix)")
            print("   - íŠ¸ëœì­ì…˜ & ë¡¤ë°± ì‹œìŠ¤í…œ")
            print("   - ë°±ë§í¬ ë„¤íŠ¸ì›Œí¬ ì¶”ì ")
            print("   - íŒŒì¼ í†µê³„ ë° í† í° ì¶”ì •")
            print("\nğŸ“ ë‹¤ìŒ ë‹¨ê³„:")
            print("   - python src/mcp_server.py ë¡œ ì„œë²„ ì‹œì‘")
            print("   - Auto-update ì„œë¹„ìŠ¤ í™œì„±í™” (Phase 2)")
            print("   - Repomix íŒ¨í‚¹ ë„êµ¬ ì‚¬ìš© (Phase 3)")
        else:
            print(
                "\nğŸ’¡ ì‹¤ì œ ë§ˆì´ê·¸ë ˆì´ì…˜ì„ ìˆ˜í–‰í•˜ë ¤ë©´ --dry-run í”Œë˜ê·¸ ì—†ì´ ì‹¤í–‰í•˜ì„¸ìš”."
            )

        print()

        return 0

    except Exception as e:
        print(colored(f"\nâŒ ì˜ˆìƒì¹˜ ëª»í•œ ì˜¤ë¥˜: {e}", Colors.FAIL))
        if args.verbose:
            traceback.print_exc()
        print(colored(f"\nğŸ’¡ ë¡¤ë°± ë°©ë²•: python {__file__} --rollback", Colors.OKCYAN))
        return 1


if __name__ == "__main__":
    sys.exit(main())
