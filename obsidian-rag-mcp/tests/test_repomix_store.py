import json
import tempfile
from datetime import datetime, timedelta
from pathlib import Path

import pytest

from src.repomix_store import RepomixIndexStore


@pytest.fixture
def temp_index_file():
    """ì„ì‹œ ì¸ë±ìŠ¤ íŒŒì¼ ìƒì„±"""
    with tempfile.NamedTemporaryFile(mode="w", delete=False, suffix=".json") as f:
        temp_path = Path(f.name)
    yield temp_path
    # í…ŒìŠ¤íŠ¸ í›„ íŒŒì¼ ì‚­ì œ
    if temp_path.exists():
        temp_path.unlink()


@pytest.fixture
def sample_content():
    """í…ŒìŠ¤íŠ¸ìš© ìƒ˜í”Œ ì»¨í…ì¸ """
    return """# AI Strategy 2025

This is a comprehensive strategy document for implementing AI initiatives.

## Key Points
- Machine learning adoption
- Data infrastructure
- Ethical AI framework

Tags: #ai #strategy #2025

References:
- [[Project A]]
- [[Roadmap 2025]]
- [[Tech Stack]]
"""


@pytest.fixture
def sample_doc():
    """í…ŒìŠ¤íŠ¸ìš© ìƒ˜í”Œ ë¬¸ì„œ"""
    return {
        "path": "/vault/00 Notes/Work/AI Strategy 2025.md",
        "title": "AI Strategy 2025",
        "content": """# AI Strategy 2025

This is a comprehensive strategy document for implementing AI initiatives.

## Key Points
- Machine learning adoption
- Data infrastructure
- Ethical AI framework

Tags: #ai #strategy #2025

References:
- [[Project A]]
- [[Roadmap 2025]]
- [[Tech Stack]]
""",
        "metadata": {"tags": ["ai", "strategy"]},
        "tags": ["ai", "strategy", "2025"],
        "wiki_links": ["Project A", "Roadmap 2025", "Tech Stack"],
        "backlinks": ["Project A", "Roadmap 2025"],
        "para_folder": "00 Notes",
    }


def test_init_creates_empty_index(temp_index_file):
    """ì´ˆê¸°í™” ì‹œ ë¹ˆ ì¸ë±ìŠ¤ ìƒì„± í…ŒìŠ¤íŠ¸"""
    store = RepomixIndexStore(temp_index_file)
    assert store.index["version"] == "1.0.0"
    assert store.index["files"] == {}
    assert store.index["stats"]["total_files"] == 0


def test_calculate_stats(temp_index_file, sample_content):
    """íŒŒì¼ í†µê³„ ê³„ì‚° í…ŒìŠ¤íŠ¸"""
    store = RepomixIndexStore(temp_index_file)

    # ì„ì‹œ íŒŒì¼ ìƒì„±
    with tempfile.NamedTemporaryFile(
        mode="w", delete=False, suffix=".md", encoding="utf-8"
    ) as f:
        f.write(sample_content)
        temp_file = Path(f.name)

    try:
        stats = store.calculate_stats(sample_content, temp_file)

        # ê¸°ë³¸ í†µê³„ ê²€ì¦
        assert stats["words"] > 0
        assert stats["characters"] > 0
        assert stats["lines"] > 0
        assert stats["estimated_tokens"] > 0

        # ë‹¨ì–´ ìˆ˜ ê²€ì¦ (ëŒ€ëµì ì¸ ë²”ìœ„)
        assert 30 < stats["words"] < 50

        # í† í° ìˆ˜ê°€ ë‹¨ì–´ ìˆ˜ë³´ë‹¤ ë§ì•„ì•¼ í•¨ (ì˜ì–´ ê¸°ì¤€)
        assert stats["estimated_tokens"] >= stats["words"]

        print("\nğŸ“Š í†µê³„ ê³„ì‚° ê²°ê³¼:")
        print(f"  - ë‹¨ì–´: {stats['words']}")
        print(f"  - ë¬¸ì: {stats['characters']}")
        print(f"  - ì¤„: {stats['lines']}")
        print(f"  - í† í°: {stats['estimated_tokens']}")
        print(f"  - í† í°/ë‹¨ì–´ ë¹„ìœ¨: {stats['estimated_tokens']/stats['words']:.2f}")

    finally:
        temp_file.unlink()


def test_update_and_save_index(temp_index_file, sample_doc):
    """ì¸ë±ìŠ¤ ì—…ë°ì´íŠ¸ ë° ì €ì¥ í…ŒìŠ¤íŠ¸"""
    store = RepomixIndexStore(temp_index_file)

    # ì„ì‹œ íŒŒì¼ ìƒì„±
    with tempfile.NamedTemporaryFile(
        mode="w", delete=False, suffix=".md", encoding="utf-8"
    ) as f:
        f.write(sample_doc["content"])
        temp_file = Path(f.name)

    try:
        # ì¸ë±ìŠ¤ ì—…ë°ì´íŠ¸
        store.update_index(sample_doc, temp_file)

        # íŒŒì¼ ì •ë³´ í™•ì¸
        path_str = str(temp_file)
        assert path_str in store.index["files"]

        file_info = store.index["files"][path_str]
        assert file_info["title"] == "AI Strategy 2025"
        assert file_info["para_folder"] == "00 Notes"
        assert "timestamps" in file_info
        assert "size" in file_info
        assert file_info["metadata"]["tags"] == ["ai", "strategy", "2025"]

        # ì €ì¥ í…ŒìŠ¤íŠ¸
        store.save_index()
        assert temp_index_file.exists()

        # ì €ì¥ëœ íŒŒì¼ ë¡œë“œí•˜ì—¬ ê²€ì¦
        with open(temp_index_file, "r", encoding="utf-8") as f:
            saved_index = json.load(f)
            assert saved_index["stats"]["total_files"] == 1
            assert saved_index["stats"]["total_words"] > 0

    finally:
        temp_file.unlink()


def test_delete_index(temp_index_file, sample_doc):
    """ì¸ë±ìŠ¤ ì‚­ì œ í…ŒìŠ¤íŠ¸"""
    store = RepomixIndexStore(temp_index_file)

    # ì„ì‹œ íŒŒì¼ ìƒì„± ë° ì¸ë±ìŠ¤ ì¶”ê°€
    with tempfile.NamedTemporaryFile(
        mode="w", delete=False, suffix=".md", encoding="utf-8"
    ) as f:
        f.write(sample_doc["content"])
        temp_file = Path(f.name)

    try:
        path_str = str(temp_file)
        store.update_index(sample_doc, temp_file)
        assert path_str in store.index["files"]

        # ì‚­ì œ
        store.delete_index(path_str)
        assert path_str not in store.index["files"]

    finally:
        temp_file.unlink()


def test_query_by_timeframe(temp_index_file):
    """ì‹œê°„ ë²”ìœ„ ì¿¼ë¦¬ í…ŒìŠ¤íŠ¸"""
    store = RepomixIndexStore(temp_index_file)

    # ìµœê·¼ íŒŒì¼ê³¼ ì˜¤ë˜ëœ íŒŒì¼ ì¶”ê°€
    with tempfile.NamedTemporaryFile(
        mode="w", delete=False, suffix=".md", encoding="utf-8"
    ) as f:
        f.write("Recent note")
        recent_file = Path(f.name)

    with tempfile.NamedTemporaryFile(
        mode="w", delete=False, suffix=".md", encoding="utf-8"
    ) as f:
        f.write("Old note")
        old_file = Path(f.name)

    try:
        # ìµœê·¼ íŒŒì¼ ì¶”ê°€
        recent_doc = {
            "title": "Recent Note",
            "content": "Recent note",
            "para_folder": "00 Notes",
            "tags": [],
            "wiki_links": [],
            "backlinks": [],
        }
        store.update_index(recent_doc, recent_file)

        # ì˜¤ë˜ëœ íŒŒì¼ ì¶”ê°€ (íƒ€ì„ìŠ¤íƒ¬í”„ ì¡°ì‘)
        old_doc = {
            "title": "Old Note",
            "content": "Old note",
            "para_folder": "00 Notes",
            "tags": [],
            "wiki_links": [],
            "backlinks": [],
        }
        store.update_index(old_doc, old_file)

        # ì˜¤ë˜ëœ íŒŒì¼ì˜ íƒ€ì„ìŠ¤íƒ¬í”„ë¥¼ 30ì¼ ì „ìœ¼ë¡œ ì„¤ì •
        old_timestamp = (datetime.now() - timedelta(days=30)).isoformat()
        store.index["files"][str(old_file)]["timestamps"]["modified"] = old_timestamp

        # ìµœê·¼ 7ì¼ ì´ë‚´ íŒŒì¼ ì¿¼ë¦¬
        results = store.query_by_timeframe(days=7)
        assert len(results) == 1
        assert results[0]["title"] == "Recent Note"

        # ìµœê·¼ 60ì¼ ì´ë‚´ íŒŒì¼ ì¿¼ë¦¬
        results = store.query_by_timeframe(days=60)
        assert len(results) == 2

    finally:
        recent_file.unlink()
        old_file.unlink()


def test_query_by_tag(temp_index_file, sample_doc):
    """íƒœê·¸ ì¿¼ë¦¬ í…ŒìŠ¤íŠ¸"""
    store = RepomixIndexStore(temp_index_file)

    with tempfile.NamedTemporaryFile(
        mode="w", delete=False, suffix=".md", encoding="utf-8"
    ) as f:
        f.write(sample_doc["content"])
        temp_file = Path(f.name)

    try:
        store.update_index(sample_doc, temp_file)

        # 'ai' íƒœê·¸ë¡œ ê²€ìƒ‰
        results = store.query_by_tag("ai")
        assert len(results) == 1
        assert results[0]["title"] == "AI Strategy 2025"

        # ì—†ëŠ” íƒœê·¸ë¡œ ê²€ìƒ‰
        results = store.query_by_tag("nonexistent")
        assert len(results) == 0

    finally:
        temp_file.unlink()


def test_get_by_title(temp_index_file, sample_doc):
    """ì œëª©ìœ¼ë¡œ ê²€ìƒ‰ í…ŒìŠ¤íŠ¸"""
    store = RepomixIndexStore(temp_index_file)

    with tempfile.NamedTemporaryFile(
        mode="w", delete=False, suffix=".md", encoding="utf-8"
    ) as f:
        f.write(sample_doc["content"])
        temp_file = Path(f.name)

    try:
        store.update_index(sample_doc, temp_file)

        # ì œëª©ìœ¼ë¡œ ê²€ìƒ‰
        result = store.get_by_title("AI Strategy 2025")
        assert result is not None
        assert result["title"] == "AI Strategy 2025"

        # ì—†ëŠ” ì œëª©ìœ¼ë¡œ ê²€ìƒ‰
        result = store.get_by_title("Nonexistent Note")
        assert result is None

    finally:
        temp_file.unlink()


def test_get_folder_stats(temp_index_file):
    """í´ë” í†µê³„ í…ŒìŠ¤íŠ¸"""
    store = RepomixIndexStore(temp_index_file)

    # ì—¬ëŸ¬ í´ë”ì˜ íŒŒì¼ ì¶”ê°€
    docs = [
        {
            "title": "Note 1",
            "content": "Content " * 100,
            "para_folder": "00 Notes",
            "tags": [],
            "wiki_links": [],
            "backlinks": [],
        },
        {
            "title": "Note 2",
            "content": "Content " * 200,
            "para_folder": "00 Notes",
            "tags": [],
            "wiki_links": [],
            "backlinks": [],
        },
        {
            "title": "Ref 1",
            "content": "Content " * 50,
            "para_folder": "01 Reference",
            "tags": [],
            "wiki_links": [],
            "backlinks": [],
        },
    ]

    temp_files = []
    try:
        for doc in docs:
            with tempfile.NamedTemporaryFile(
                mode="w", delete=False, suffix=".md", encoding="utf-8"
            ) as f:
                f.write(doc["content"])
                temp_file = Path(f.name)
                temp_files.append(temp_file)
                store.update_index(doc, temp_file)

        # í´ë” í†µê³„ í™•ì¸
        folder_stats = store.get_folder_stats()
        assert "00 Notes" in folder_stats
        assert "01 Reference" in folder_stats

        assert folder_stats["00 Notes"]["files"] == 2
        assert folder_stats["01 Reference"]["files"] == 1

        assert folder_stats["00 Notes"]["words"] > folder_stats["01 Reference"]["words"]

    finally:
        for f in temp_files:
            f.unlink()


def test_get_tag_stats(temp_index_file):
    """íƒœê·¸ í†µê³„ í…ŒìŠ¤íŠ¸"""
    store = RepomixIndexStore(temp_index_file)

    # ì—¬ëŸ¬ íƒœê·¸ë¥¼ ê°€ì§„ íŒŒì¼ë“¤ ì¶”ê°€
    docs = [
        {
            "title": "Note 1",
            "content": "Content",
            "para_folder": "00 Notes",
            "tags": ["ai", "strategy"],
            "wiki_links": [],
            "backlinks": [],
        },
        {
            "title": "Note 2",
            "content": "Content",
            "para_folder": "00 Notes",
            "tags": ["ai", "machine-learning"],
            "wiki_links": [],
            "backlinks": [],
        },
        {
            "title": "Note 3",
            "content": "Content",
            "para_folder": "00 Notes",
            "tags": ["ai"],
            "wiki_links": [],
            "backlinks": [],
        },
    ]

    temp_files = []
    try:
        for doc in docs:
            with tempfile.NamedTemporaryFile(
                mode="w", delete=False, suffix=".md", encoding="utf-8"
            ) as f:
                f.write(doc["content"])
                temp_file = Path(f.name)
                temp_files.append(temp_file)
                store.update_index(doc, temp_file)

        # íƒœê·¸ í†µê³„ í™•ì¸
        tag_stats = store.get_tag_stats()
        assert tag_stats["ai"] == 3
        assert tag_stats["strategy"] == 1
        assert tag_stats["machine-learning"] == 1

        # ë¹ˆë„ìˆœ ì •ë ¬ í™•ì¸
        tags_list = list(tag_stats.keys())
        assert tags_list[0] == "ai"  # ê°€ì¥ ë§ì´ ì‚¬ìš©ëœ íƒœê·¸

    finally:
        for f in temp_files:
            f.unlink()


def test_token_estimation_accuracy(temp_index_file):
    """í† í° ì¶”ì • ì •í™•ë„ í…ŒìŠ¤íŠ¸"""
    store = RepomixIndexStore(temp_index_file)

    # ë‹¤ì–‘í•œ ê¸¸ì´ì˜ í…ìŠ¤íŠ¸ë¡œ í…ŒìŠ¤íŠ¸
    test_cases = [
        ("Short text", 2),  # ì§§ì€ í…ìŠ¤íŠ¸
        ("Medium " * 50, 50),  # ì¤‘ê°„ ê¸¸ì´
        ("Long text with many words " * 200, 400),  # ê¸´ í…ìŠ¤íŠ¸
    ]

    for content, expected_min_tokens in test_cases:
        with tempfile.NamedTemporaryFile(
            mode="w", delete=False, suffix=".md", encoding="utf-8"
        ) as f:
            f.write(content)
            temp_file = Path(f.name)

        try:
            stats = store.calculate_stats(content, temp_file)

            # í† í° ìˆ˜ê°€ ë‹¨ì–´ ìˆ˜ë³´ë‹¤ ì ì§€ ì•Šì•„ì•¼ í•¨
            assert stats["estimated_tokens"] >= stats["words"] * 0.7

            # ì˜ˆìƒ ìµœì†Œ í† í° ìˆ˜ í™•ì¸
            assert stats["estimated_tokens"] >= expected_min_tokens

            print(
                f"\nğŸ” '{content[:30]}...': {stats['words']}ë‹¨ì–´ â†’ {stats['estimated_tokens']}í† í°"
            )

        finally:
            temp_file.unlink()


if __name__ == "__main__":
    pytest.main([__file__, "-v", "-s"])
